import streamlit as st
import os
from PIL import Image
from langchain_community.document_loaders import PDFPlumberLoader, UnstructuredFileLoader
from langchain_experimental.text_splitter import SemanticChunker
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.llms import Ollama
from langchain.prompts import PromptTemplate
from langchain.chains.llm import LLMChain
from langchain.chains.combine_documents.stuff import StuffDocumentsChain
from langchain.chains import RetrievalQA
import matplotlib.pyplot as plt
import numpy as np
import pytesseract

pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
# ‚úÖ NgƒÉn l·ªói torch.classes do Streamlit Watcher
os.environ["STREAMLIT_WATCH_DISABLE"] = "true"

# ========== UI Customization ==========
st.set_page_config(page_title="CV & JD Matching", layout="centered")
logo = Image.open("logo2.jpg")
st.image(logo)
primary_color = "#1E90FF"
secondary_color = "#FF6347"
background_color = "#F5F5F5"
text_color = "#4561e9"

st.markdown(f"""
    <style>
    .stApp {{
        background-color: {background_color};
        color: {text_color};
    }}
    .stButton>button {{
        background-color: {primary_color};
        color: white;
        border-radius: 5px;
        border: none;
        padding: 10px 20px;
        font-size: 16px;
    }}
    .stFileUploader>div>div>div>button {{
        background-color: {secondary_color};
        color: white;
        border-radius: 5px;
        border: none;
        padding: 10px 20px;
        font-size: 16px;
    }}
    </style>
""", unsafe_allow_html=True)

st.title("\U0001F4C4 CV & JD")

# ========== Upload ==========
cv_file = st.file_uploader("Upload CV", type=["pdf", "docx", "png", "jpg", "jpeg"], key="cv")
jd_file = st.file_uploader("Upload JD", type=["pdf", "docx", "png", "jpg", "jpeg"], key="jd")


# ========== Embedding Model ==========
@st.cache_resource
def get_similarity_model():
    from sentence_transformers import SentenceTransformer
    return SentenceTransformer("all-MiniLM-L6-v2")


def calculate_similarity(text1, text2):
    if not text1 or not text2:
        return 0.0
    from sentence_transformers import util
    model = get_similarity_model()
    emb1 = model.encode(text1, convert_to_tensor=True)
    emb2 = model.encode(text2, convert_to_tensor=True)
    return round(util.pytorch_cos_sim(emb1, emb2).item(), 2)


# ========== Radar Chart ==========
def draw_radar(scores_dict):
    labels = list(scores_dict.keys())
    values = list(scores_dict.values())
    angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()
    values += values[:1]
    angles += angles[:1]

    fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))
    ax.plot(angles, values, 'o-', linewidth=2)
    ax.fill(angles, values, alpha=0.25)
    ax.set_thetagrids(np.degrees(angles[:-1]), labels)
    ax.set_ylim(0, 100)
    ax.set_title("Bi·ªÉu ƒë·ªì ƒë√°nh gi√° m·ª©c ƒë·ªô ph√π h·ª£p", fontsize=16)
    st.pyplot(fig)


# ========== Prompt ==========
system_prompt = PromptTemplate.from_template("""
B·∫°n ƒëang ƒë√≥ng vai tr√≤ l√† m·ªôt chuy√™n gia tuy·ªÉn d·ª•ng c√≥ kinh nghi·ªám trong vi·ªác ƒë√°nh gi√° m·ª©c ƒë·ªô ph√π h·ª£p gi·ªØa h·ªì s∆° ·ª©ng vi√™n (CV) v√† b·∫£n m√¥ t·∫£ c√¥ng vi·ªác (JD). 
D·ª±a tr√™n c√°c th√¥ng tin trong ph·∫ßn context d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch trung th·ª±c v√† kh√°ch quan.

- N·∫øu th√¥ng tin kh√¥ng ƒë·ªß ƒë·ªÉ tr·∫£ l·ªùi, h√£y tr·∫£ l·ªùi "T√¥i kh√¥ng ch·∫Øc d·ª±a tr√™n th√¥ng tin hi·ªán t·∫°i".
- Kh√¥ng suy ƒëo√°n ho·∫∑c b·ªãa ƒë·∫∑t th√¥ng tin kh√¥ng c√≥ trong context.

Context: {context}
Question: {question}
Tr·∫£ l·ªùi chi ti·∫øt v√† ch√≠nh x√°c:
""")


# ========== QA Builder ==========
@st.cache_resource
def build_qa_chain(uploaded_file):
    file_name = "temp_" + uploaded_file.name
    with open(file_name, "wb") as f:
        f.write(uploaded_file.getvalue())

    ext = uploaded_file.name.split(".")[-1].lower()
    if ext in ["jpg", "jpeg", "png"]:
        image = Image.open(file_name)
        extracted_text = pytesseract.image_to_string(image, lang='eng')
        # st.text_area("üñº VƒÉn b·∫£n tr√≠ch xu·∫•t t·ª´ ·∫£nh:", extracted_text, height=200)
        if not extracted_text.strip():
            st.warning("‚ö†Ô∏èKh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c vƒÉn b·∫£n t·ª´ ·∫£nh.")
            return lambda q: "Kh√¥ng c√≥ n·ªôi dung vƒÉn b·∫£n trong ·∫£nh ƒë·ªÉ ph√¢n t√≠ch."

        def qa_fn(question):
            llm = Ollama(model="deepseek-coder-v2:16b", temperature=0.1)
            prompt = system_prompt.format(context=extracted_text, question=question)
            return llm.invoke(prompt)

        return qa_fn

    # PDF or DOCX
    if ext == "pdf":
        loader = PDFPlumberLoader(file_name)
    else:
        loader = UnstructuredFileLoader(file_name)
    docs = loader.load()

    embedder = HuggingFaceEmbeddings()
    splitter = SemanticChunker(embedder)
    chunks = splitter.split_documents(docs)
    vector = FAISS.from_documents(chunks, embedder)
    retriever = vector.as_retriever(search_type="similarity", search_kwargs={"k": 3})

    llm = Ollama(model="deepseek-coder-v2:16b", temperature=0.1)
    llm_chain = LLMChain(llm=llm, prompt=system_prompt)
    combine_docs_chain = StuffDocumentsChain(
        llm_chain=llm_chain,
        document_variable_name="context",
        document_prompt=PromptTemplate(
            input_variables=["page_content", "source"],
            template="Context:\ncontent:{page_content}\nsource:{source}"
        )
    )
    qa_chain = RetrievalQA(combine_documents_chain=combine_docs_chain, retriever=retriever)

    def qa_fn(question):
        return qa_chain.run(question).strip()

    return qa_fn


# ========== Evaluation ==========
if cv_file and jd_file:
    with st.spinner("üîç ƒêang ph√¢n t√≠ch CV v√† JD..."):
        cv_qa = build_qa_chain(cv_file)
        jd_qa = build_qa_chain(jd_file)

        fields = {
            "K·ªπ nƒÉng": "Li·ªát k√™ t·∫•t c·∫£ k·ªπ nƒÉng c·ªßa ·ª©ng vi√™n.",
            "H·ªçc v·∫•n": "Tr√¨nh ƒë·ªô h·ªçc v·∫•n c·ªßa ·ª©ng vi√™n l√† g√¨?",
            "Kinh nghi·ªám": "·ª®ng vi√™n c√≥ kinh nghi·ªám g√¨?",
            "B·∫±ng c·∫•p": "·ª®ng vi√™n c√≥ nh·ªØng b·∫±ng c·∫•p n√†o?",
            "V·ªã tr√≠ mong mu·ªën": "V·ªã tr√≠ ·ª©ng vi√™n mong mu·ªën l√† g√¨?"
        }

        total_score = 0
        radar_scores = {}
        st.subheader("K·∫øt qu·∫£ ƒë√°nh gi√° t·ª´ng m·ª•c")

        for name, question in fields.items():
            cv_answer = cv_qa(question)
            jd_question = f"Job description y√™u c·∫ßu g√¨ v·ªÅ: {name.lower()}?"
            jd_answer = jd_qa(jd_question)
            score = calculate_similarity(cv_answer, jd_answer)
            total_score += score
            radar_scores[name] = score * 100

            with st.expander(f"üîç {name} (T∆∞∆°ng ƒë·ªìng: {score * 100:.0f}%)"):
                st.markdown(f"**T·ª´ CV:** {cv_answer or 'Kh√¥ng t√¨m th·∫•y'}")
                st.markdown(f"**T·ª´ JD:** {jd_answer or 'Kh√¥ng t√¨m th·∫•y'}")

        avg_score = total_score / len(fields)
        st.success(f"M·ª©c ƒë·ªô ph√π h·ª£p t·ªïng th·ªÉ: **{avg_score * 100:.0f}%**")
        draw_radar(radar_scores)
else:
    st.warning("Vui l√≤ng upload **c·∫£ CV** v√† **JD** ƒë·ªÉ h·ªá th·ªëng ph√¢n t√≠ch.")
